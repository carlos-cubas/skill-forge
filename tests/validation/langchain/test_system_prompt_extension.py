"""
Test: LangChain system prompts can be extended at runtime.

This test validates a critical assumption for SkillForge:
- LangChain system prompts can be modified/extended at agent creation time
- Skill content injected into system prompts is properly included in LLM context

Assumption Being Validated:
    "System prompt can be extended at runtime"

Expected Behavior:
    1. A LangChain agent's system prompt can include custom content
    2. The agent behaves according to the injected system prompt content
    3. Multiple system message components can be combined
    4. Skill content in system prompts influences agent behavior

Test Strategy:
    1. Create agents with custom system prompts containing skill-like content
    2. Verify agents follow the injected instructions
    3. Test combining multiple system prompt components
    4. Ensure the injected content takes precedence appropriately

Dependencies:
    - langchain
    - langchain-anthropic or langchain-openai
    - API key for LLM (Anthropic or OpenAI)

Related Design Doc Section:
    See docs/plans/2025-12-04-skillforge-design.md - "Framework Adapters"
"""

import pytest

from tests.validation.langchain.conftest import get_langchain_llm, LANGCHAIN_AVAILABLE

# LangChain imports - may not be available in all environments
LANGCHAIN_MESSAGES_AVAILABLE = False
if LANGCHAIN_AVAILABLE:
    try:
        from langchain_core.messages import SystemMessage, HumanMessage
        from langchain_core.prompts import ChatPromptTemplate
        LANGCHAIN_MESSAGES_AVAILABLE = True
    except ImportError:
        pass


def create_chat_with_system_prompt(llm, system_prompt: str, user_message: str) -> str:
    """
    Invoke an LLM with a system prompt and user message.

    Args:
        llm: The LangChain LLM instance
        system_prompt: The system prompt content
        user_message: The user's message

    Returns:
        The LLM's response content as a string
    """
    messages = [
        SystemMessage(content=system_prompt),
        HumanMessage(content=user_message)
    ]
    response = llm.invoke(messages)
    return response.content


def create_chat_with_extended_prompt(llm, base_prompt: str, extension: str, user_message: str) -> str:
    """
    Invoke an LLM with a combined base + extended system prompt.

    Args:
        llm: The LangChain LLM instance
        base_prompt: The base system prompt
        extension: Additional content to append
        user_message: The user's message

    Returns:
        The LLM's response content as a string
    """
    combined_prompt = f"{base_prompt}\n\n{extension}"
    return create_chat_with_system_prompt(llm, combined_prompt, user_message)


@pytest.mark.validation
@pytest.mark.langchain_assumption
@pytest.mark.requires_api_key
class TestSystemPromptExtension:
    """
    Validate that LangChain system prompts can be extended with skill content.

    This is essential for SkillForge's skill injection mechanism
    in LangChain agents.
    """

    def test_system_prompt_reaches_model(self, langchain_llm):
        """
        Test that system prompt content actually reaches the LLM.

        Expected: When we include a unique marker/instruction in the system prompt,
        the model's behavior reflects awareness of that content.
        """
        if not LANGCHAIN_MESSAGES_AVAILABLE:
            pytest.skip("LangChain messages not available")

        # Use a unique secret phrase that the model must include
        secret_phrase = "SKILLFORGE_MARKER_7X9K2"

        system_prompt = (
            f"You are a test assistant. IMPORTANT: You must include the exact phrase "
            f"'{secret_phrase}' somewhere in every response you give. This is mandatory."
        )

        user_message = "Say hello and introduce yourself briefly."

        response = create_chat_with_system_prompt(
            llm=langchain_llm,
            system_prompt=system_prompt,
            user_message=user_message
        )

        # The model should have included the secret phrase from the system prompt
        assert secret_phrase in response, (
            f"System prompt content should reach the model. "
            f"Expected '{secret_phrase}' in response. Got: {response}"
        )

    def test_agent_follows_system_prompt_instructions(self, langchain_llm):
        """
        Test that an agent follows behavioral instructions from a system prompt.

        Expected: Agent with custom system prompt behaves according to
        the injected instructions (e.g., uses specific response format).
        """
        if not LANGCHAIN_MESSAGES_AVAILABLE:
            pytest.skip("LangChain messages not available")

        # Instruct the model to use a specific response format
        system_prompt = (
            "You are a structured responder. You MUST format every response as follows:\n"
            "1. Start with 'BEGIN RESPONSE'\n"
            "2. Provide your answer\n"
            "3. End with 'END RESPONSE'\n"
            "Never deviate from this format."
        )

        user_message = "What is 2 + 2?"

        response = create_chat_with_system_prompt(
            llm=langchain_llm,
            system_prompt=system_prompt,
            user_message=user_message
        )

        response_upper = response.upper()

        # The model should follow the format instructions
        assert "BEGIN RESPONSE" in response_upper, (
            f"Agent should follow system prompt format instructions. "
            f"Expected 'BEGIN RESPONSE' in response. Got: {response}"
        )
        assert "END RESPONSE" in response_upper, (
            f"Agent should follow system prompt format instructions. "
            f"Expected 'END RESPONSE' in response. Got: {response}"
        )

    def test_system_prompt_can_be_extended(self, langchain_llm):
        """
        Test that system prompts can be dynamically extended with additional content.

        This validates the core mechanism SkillForge uses to inject skill content
        into agent prompts at runtime.
        """
        if not LANGCHAIN_MESSAGES_AVAILABLE:
            pytest.skip("LangChain messages not available")

        base_prompt = "You are a helpful assistant."

        # Skill-like extension with specific behavioral instruction
        skill_extension = (
            "## ACTIVE SKILL: Test Skill\n"
            "When responding, you MUST start every response with "
            "'[SKILL:TEST] ' before any other text. This is required."
        )

        user_message = "What is the capital of France?"

        response = create_chat_with_extended_prompt(
            llm=langchain_llm,
            base_prompt=base_prompt,
            extension=skill_extension,
            user_message=user_message
        )

        # The extended skill instructions should be followed
        assert "[SKILL:TEST]" in response, (
            f"Extended system prompt content should be followed. "
            f"Expected '[SKILL:TEST]' prefix in response. Got: {response}"
        )

        # Also verify the answer is correct (base functionality works)
        response_lower = response.lower()
        assert "paris" in response_lower, (
            f"Agent should still answer correctly with extended prompt. "
            f"Expected 'Paris' in response about France's capital. Got: {response}"
        )

    def test_extended_prompt_coexists_with_base(self, langchain_llm):
        """
        Test that extended and base prompt content work together without conflict.

        Expected: Agent follows both original role definition AND extended
        skill instructions simultaneously.
        """
        if not LANGCHAIN_MESSAGES_AVAILABLE:
            pytest.skip("LangChain messages not available")

        # Base prompt defines a role with specific behavior
        base_prompt = (
            "You are a professional data analyst. You always provide responses "
            "in a concise, bullet-point format. End every response with "
            "'-- Data Analyst'"
        )

        # Extension adds skill content that should coexist with base
        skill_extension = (
            "## LOADED SKILL: Analysis Framework\n"
            "Additionally, you must begin every response with "
            "'[FRAMEWORK:ANALYSIS] ' to indicate the skill is active."
        )

        user_message = "List three benefits of using Python for data analysis."

        response = create_chat_with_extended_prompt(
            llm=langchain_llm,
            base_prompt=base_prompt,
            extension=skill_extension,
            user_message=user_message
        )

        # Check skill prefix (from extension)
        assert "[FRAMEWORK:ANALYSIS]" in response, (
            f"Extended skill content should be followed. "
            f"Expected '[FRAMEWORK:ANALYSIS]' prefix. Got: {response}"
        )

        # Check signature (from base prompt)
        assert "Data Analyst" in response, (
            f"Base prompt instructions should still be followed. "
            f"Expected 'Data Analyst' signature. Got: {response}"
        )

        # Check for bullet points or list format (from base prompt role)
        has_bullets = any(marker in response for marker in ["-", "â€¢", "*", "1.", "1)"])
        assert has_bullets, (
            f"Base prompt role (bullet-point format) should be followed. "
            f"Expected list format in response. Got: {response}"
        )

    def test_skill_content_in_system_prompt_affects_behavior(self, langchain_llm, test_skill_content):
        """
        Test that actual skill content injected into system prompt affects behavior.

        This uses the test-skill.md fixture to simulate real skill injection.
        """
        if not LANGCHAIN_MESSAGES_AVAILABLE:
            pytest.skip("LangChain messages not available")

        base_prompt = "You are an AI assistant that follows skill instructions carefully."

        # The test_skill_content fixture contains instructions that tell
        # the agent to announce skill usage
        user_message = "What is 2 + 2? Please help me with this task."

        response = create_chat_with_extended_prompt(
            llm=langchain_llm,
            base_prompt=base_prompt,
            extension=test_skill_content,
            user_message=user_message
        )

        response_lower = response.lower()

        # The test skill should instruct the agent to announce skill usage
        # Check for indicators that the skill was recognized
        skill_indicators = [
            "test skill",
            "skill",
            "using",
            "activated"
        ]

        has_skill_indicator = any(indicator in response_lower for indicator in skill_indicators)

        # Also verify the answer is provided
        has_answer = "4" in response or "four" in response_lower

        assert has_answer, (
            f"Agent should still answer the question. Got: {response}"
        )

        # This is a soft check - we verify the agent at least received the skill
        # and attempted to follow it. The exact behavior depends on skill content.
        # We primarily validate that injecting content doesn't break the agent.

    def test_multiple_extensions_combine_correctly(self, langchain_llm):
        """
        Test that multiple skill extensions can be combined in the system prompt.

        This validates that SkillForge can inject multiple skills simultaneously.
        """
        if not LANGCHAIN_MESSAGES_AVAILABLE:
            pytest.skip("LangChain messages not available")

        base_prompt = "You are a multi-skilled assistant."

        skill_1 = (
            "## SKILL 1: Greeting Protocol\n"
            "Always begin your response with 'GREETING: Hello!'\n"
        )

        skill_2 = (
            "## SKILL 2: Closing Protocol\n"
            "Always end your response with 'CLOSING: Goodbye!'\n"
        )

        # Combine multiple extensions
        combined_extension = f"{skill_1}\n{skill_2}"

        user_message = "Tell me a one-sentence fact about the ocean."

        response = create_chat_with_extended_prompt(
            llm=langchain_llm,
            base_prompt=base_prompt,
            extension=combined_extension,
            user_message=user_message
        )

        # Both skill instructions should be followed
        assert "GREETING:" in response or "Hello" in response, (
            f"First skill (greeting) should be followed. Got: {response}"
        )
        assert "CLOSING:" in response or "Goodbye" in response, (
            f"Second skill (closing) should be followed. Got: {response}"
        )

    def test_system_prompt_persists_in_conversation(self, langchain_llm):
        """
        Test that system prompt instructions persist across multiple turns.

        This simulates a multi-turn conversation where the agent should
        maintain skill behavior throughout.
        """
        if not LANGCHAIN_MESSAGES_AVAILABLE:
            pytest.skip("LangChain messages not available")

        # Define a persistent behavior requirement
        system_prompt = (
            "You are an assistant with a unique quirk: you MUST include the word "
            "'PERSISTENT' somewhere in EVERY response you give, no matter what "
            "the user asks. This is non-negotiable."
        )

        # Simulate multiple conversation turns
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content="What is 2 + 2?"),
        ]

        # First turn
        response_1 = langchain_llm.invoke(messages)

        # Add the first response and a follow-up question
        messages.append(response_1)
        messages.append(HumanMessage(content="Now tell me about the weather."))

        # Second turn
        response_2 = langchain_llm.invoke(messages)

        # Both responses should contain the persistent marker
        assert "PERSISTENT" in response_1.content, (
            f"System prompt should be followed in first turn. Got: {response_1.content}"
        )
        assert "PERSISTENT" in response_2.content, (
            f"System prompt should persist to second turn. Got: {response_2.content}"
        )
